## 任务调度平台AirflowPlus

### 项目简述

#### 项目背景

**AirflowPlus** 基于开源项目 Apache-Airflow 进行二次开发，针对任务高度并行化场景进行专门的调度优化，克服原生项目的性能瓶颈。任务高度并行化场景，尤其是数据处理密集场景与计算处理密集场景，会对原生Airflow的调度器以及MySQL造成较大压力，进而影响整体的调度性能和系统稳定性。



#### 项目内容

Apache-Airflow是开源的工作流管理平台，用于定义、调度和监控复杂的工作流，其主要功能如下：

- 支持基于时间的调度(Crontab)和基于事件的调度方式；
- 支持单机和集群式并发调度场景；
- 提供多种内置操作器，支持多种应用场景下的任务执行；
- 支持任务失败自动重试、通知、汇报等功能，对任务的执行提供可靠保证；
- 提供直观的Web界面，用于监控、管理、跟踪和调度任务；



#### 项目挑战

- 调度器性能瓶颈：
  - 在任务高度并行化的场景下，调度器需要快速处理大量任务的调度；
  - Apache-Airflow每5分钟对DAG目录进行全盘扫描，解析并生成任务调度信息，由于磁盘IO与实时解析，该过程需要大量时间，容易造成性能瓶颈问题；
    - 基于预加载策略，提前解析、生成、缓存任务调度信息，代替原生Airflow的实时扫描和解析，避免高负载场景下调度器性能瓶颈引起的调度问题；
- 数据库性能瓶颈：
  - 在分布式调度场景下，任务调度的触发、跟踪等功能都依赖MySQL。然而属于同一个DAG的多个并行任务可能频繁修改相同的数据行，即存在伪共享问题，这会导致MySQL成为性能瓶颈；
    - 基于合并更新策略，避免多任务频繁访问修改MySQL中的共享数据，降低MySQL读写压力，确保系统整体调度稳定性；



### 项目架构及设计

#### 总架构

![](https://github.com/YMEN6/ProjectShowcase/blob/main/picture/AirflowPlus1.png?raw=true)

- Apache-Airflow工作流程
  1. 调度器Scheduler按一定时间周期(默认5分钟)解析DAG文件(定义工作流的具体脚本文件)，将调度任务转换成Celery任务，并推送到Broker中(本项目中使用Redis作为Broker)；
  2. 分布式的任务执行器CeleryWorker从Redis中获取需要执行的任务并执行；
  3. 完成任务的执行后，CeleryWorker将MySQL中的任务状态进行更新(DAG、TaskInstance)；
  4. Scheduler根据MySQL中的任务状态，继续对任务进行跟踪、管理、调度等；
- Celery：分布式任务队列，多用于异步任务处理、定时任务调度等场景；
  - 组成：消息中间件、任务队列、工作节点和结果存储端；
  - 流程：节点从消息中间件中的任务队列中接收具体任务，在本地执行任务，并将结果存储到结果存储端；
  - 模式：Celery的各个节点间并发执行，为了避免任务重复获取、执行，Celery会使用原子操作获取任务(比如Redis中就会通过BRPOP来读取任务信息)；



#### 调度器预加载优化

![](https://github.com/YMEN6/ProjectShowcase/blob/main/picture/AirflowPlus2.png?raw=true)

- 原生Airflow
  - 调度流程
    - Scheduler每隔5分钟对DAG目录进行扫描，逐个读入、解析DAG文件，生成DAG对象，每个DAG对象都包含了一系列需要执行的任务TaskInstance；
    - Scheduler将需要调度的任务信息写入Redis，并在MySQL创建对应的数据；
  - 挑战
    - 在计算密集的场景下，许多工作流内包含大量并发的任务，其DAG文件由多个复杂的脚本文件构成，因此读入、解析需要大量的时间，且具体性能直接受限于硬盘IO的速度；
    - 在任务高度并发场景下，每个时刻都有大量的任务需要跟踪、调度和处理，单纯的延长调度性能并不能从根本上解决问题，反而可能影响调度的**实时性**和**有效性**；
- 预加载优化
  - 调整
    - 添加预加载环节，当新的DAG文件上传时，先对其进行解析，生成对应的DAG信息、任务信息与调度列表，并缓存在Redis中；
    - Scheduler在每个调度时刻，先从缓存中读取调度列表，再从缓存中读取对应的DAG信息与任务信息，避免直接从硬盘上读取解析DAG文件；
  - 提升
    - 避免了对硬盘文件的频繁读取、解析，让Scheduler将尽可能多的性能放在调度上，而不是文件读取解析上；
    - 每个时刻需要执行的任务实际只占总任务的一部分，通过提前构建调度列表，降低Scheduler的性能浪费；
    - 与完整的DAG文件相比，DAG信息、任务信息更小，且复用性高，对其缓存避免每次的重新加载时间；





#### 执行器合并更新优化

![](https://github.com/YMEN6/ProjectShowcase/blob/main/picture/AirflowPlus3.png?raw=true)

- 原生Airflow

  - 更新流程
    - 分布式场景下，Worker在执行任务后，需要将任务状态写回Redis，并更新MySQL中的DAG信息与任务信息；
  - 挑战
    - 多个并发任务在多Worker上并发执行时，MySQL中的相同DAG数据行将会被频繁修改，这会严重影响MySQL的性能，甚至导致调度卡死或出错；
    - 当Worker存在对时问题时，低并发度的调度同样可能导致调度器的逻辑异常，进而导致调度问题；

- 合并更新优化

  - 调整
    - 使用Redis作为MySQL的缓存，每个Worker将任务状态写回Redis后，也将DAG状态、时间写回Redis，并等待一段时间(10S)；
    - 初次写回DAG状态、时间时，若键值已存在，判断是否需要更新时间，若本地时间晚于缓存中的时间，则对其进行更新，否则不修改值；
    - Worker再次检查缓存中的DAG状态，若此时键值仍存在，删除键值，并更新MySQL中的DAG信息与任务信息，若键值不存在，则只更新MySQL中的任务信息(已经有其他Worker代替更新到MySQL中，且时间不早于自己写入的时间)；
  - 提升
    - 避免MySQL中相同数据行的频繁修改；
    - 减少MySQL的读写访问压力；

  